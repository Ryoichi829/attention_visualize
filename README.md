# 🧠 日本語 Self-Attention 可視化アプリ
 
このアプリは、**日本語の文に対する Self-Attention（自己注意）メカニズム**を可視化する体験型Webアプリです。

## 🎯 目的

- 日本語の文を入力すると、どの単語が重要で、また、どの単語がどの単語に注目しているかをヒートマップとして視覚化してくれます。
- このアプリを Streamlit 経由でデプロイすると、ブラウザ上で簡単に操作できます

## 🚀 主な機能

- 日本語の文章を入力すると、単語ごとの注目度（attention weight）をヒートマップで表示
- Self-Attentionの仕組みを体験的に理解
- 日本語形態素解析（janome）を使用したトークン分割
- Dropboxから日本語Wikipediaエンティティベクトル（300次元）を自動ダウンロード＆使用

## 📦 使用しているモデルについて
使用モデル：日本語Wikipediaエンティティベクトル（300次元）  
提供元：東北大学乾研究室  
モデルサイズ：約800MB  

## 🔧 モデルのダウンロードについて
1.Dropbox（作者の私用スペース）から日本語モデルをダウンロード  
　jawiki.word_vectors.300d.bin（約800MB）をDropboxから取得  
2.一時フォルダ /tmp/ に保存（ローカルにキャッシュされます）  
3.モデルのロード  
　gensimライブラリを使ってモデルを読み込みます  
4.モデルのキャッシュ化  
　@st.cache_resource を使ってStreamlitの再実行時に毎回ロードし直さないよう最適化  

## ✅ 補足
入力語が 上記モデルに存在しない場合はランダムベクトルを使っているため、多少の精度のブレあり

## ⚠️ 注意事項（モデルのダウンロードについて）
本アプリで使用している日本語Wikipediaエンティティベクトルは、開発者のDropboxアカウント上に一時的にホストされています。
将来的にリンクが無効になる可能性があり、モデルの永続的な提供は保証されていません。

リンクが切れた場合は、お手数ですがご自身でモデルを用意して attention99.py のURLを変更してください。

## ⚠️ 注意事項（多人数の同時アクセスについて）
学校の授業で使う時、40人程度での同時アクセスを行うと、メモリ不足になる。そのため、Streamlitにメモリ増強のお願いをする必要がある。

## 🪪 ライセンス
このプロジェクトは MIT ライセンスのもとで公開されています。 自由に利用・改変・再配布いただけますが、作者は一切の責任を負いません。 詳しくは LICENSE をご確認ください。

Copyright (c) 2024 かんたんAI教育ラボ
